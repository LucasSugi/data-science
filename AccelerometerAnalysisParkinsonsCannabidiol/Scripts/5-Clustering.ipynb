{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "Conforme visto no notebook anterior não foi possível obter bons resultados com dados. Assim iremos propor aqui utilizar apenas as amostras nas quais as pessoas utilizaram o Canabidiol (CBD), realizando uma clusterização em cima desses dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import pi\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "#Estilo ggplot\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setando diretorio Data como o atual\n",
    "os.chdir('../Data')\n",
    "\n",
    "#Leitura\n",
    "df_parkinson = pd.read_csv('parkinson_v2.csv',index_col = 'name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Transformação dos dados\n",
    "\n",
    "Nessa seção iremos criar os outros atributos para wpsf seguindo a fórmula wpsf = psp * pspf. Também faremos uma diminuição das features no domínio da frequência ao calcular sua média por amostra.\n",
    "\n",
    "Por fim, aplicaremos o log no intuito de distribuir mais os valores das features (existe uma assimetria muito grande) e iremos padronizá-las para o intervalo [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criacao de novas colunas\n",
    "df_parkinson['wpsf2'] = df_parkinson['pspf2'] * df_parkinson['psp2']\n",
    "df_parkinson['wpsf3'] = df_parkinson['pspf3'] * df_parkinson['psp3']\n",
    "df_parkinson.rename(columns={'wpsf':'wpsf1'},inplace=True)\n",
    "\n",
    "#Medias dos psp's e pspf's\n",
    "df_parkinson['psp'] = df_parkinson[['psp1','psp2','psp3']].apply(lambda x: x.mean(),axis=1)\n",
    "df_parkinson['pspf'] = df_parkinson[['pspf1','pspf2','pspf3']].apply(lambda x: x.mean(),axis=1)\n",
    "df_parkinson['wpsf'] = df_parkinson[['wpsf1','wpsf2','wpsf3']].apply(lambda x: x.mean(),axis=1)\n",
    "\n",
    "#Dropando colunas que nao sai mais interessantes\n",
    "y = df_parkinson['drug']\n",
    "df_parkinson = df_parkinson.drop(columns=['drug','evaluate','measure','psp1','psp2','psp3','pspf1','pspf2','pspf3','wpsf1','wpsf2','wpsf3'])\n",
    "\n",
    "#Aplicando log\n",
    "positive_cols = (df_parkinson <= 0).any()\n",
    "positive_cols = positive_cols[~positive_cols].index\n",
    "df_parkinson.loc[:,positive_cols] = np.log(df_parkinson.loc[:,positive_cols])\n",
    "\n",
    "#Reescalando variaveis\n",
    "mm = MinMaxScaler().fit(df_parkinson)\n",
    "df_parkinson.iloc[:,:] = mm.transform(df_parkinson)\n",
    "\n",
    "#Setando valor da droga novamente\n",
    "df_parkinson['drug'] = y\n",
    "\n",
    "#Dividindo datset por tipo de droga\n",
    "df_cbd = df_parkinson.loc[df_parkinson['drug'] == 'CBD']\n",
    "df_placebo = df_parkinson.loc[df_parkinson['drug'] == 'placebo']\n",
    "\n",
    "#Excluindo target por nao ser mais necessario\n",
    "del df_cbd['drug']\n",
    "del df_placebo['drug']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modelagem - Testes\n",
    "\n",
    "## 3.1 Redução de dimensionalidade e clusterização com todos os atributos\n",
    "\n",
    "Como temos muitos atributos iremos aplicar o PCA para reduzir a dimensionalidade dos dados e em seguida realizar a clusterização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Plota varios boxplot definido por x e cols'''\n",
    "def boxplot(df,cols,x):\n",
    "    \n",
    "    #Iremos plotar 3 graficos por linhas\n",
    "    ncol = 3\n",
    "    \n",
    "    #Numero de linhas é calculado automaticamente\n",
    "    nrow = int(len(cols)/3)+1\n",
    "    \n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    fig.subplots_adjust(wspace=0.3,hspace=0.3)\n",
    "    for index,c in enumerate(cols):\n",
    "        ax = fig.add_subplot(nrow,ncol,index+1)\n",
    "        ax.xaxis.label.set_size(15)\n",
    "        ax.yaxis.label.set_size(15)\n",
    "        sns.boxplot(data=df,x=x,y=c)\n",
    "    plt.show()\n",
    "    \n",
    "'''Plota um pairplot customizado'''\n",
    "def pairplot(df,col_plot,hue):\n",
    "    \n",
    "    #Pairplot\n",
    "    g = sns.pairplot(data=df,hue=hue,vars=col_plot)\n",
    "\n",
    "    #Quantidade de colunas para plotar\n",
    "    n = len(col_plot)\n",
    "    \n",
    "    #Customizando figura\n",
    "    for index in range(n):\n",
    "        \n",
    "        #Muda o tamanho de xticklabels \n",
    "        for tick_x in g.axes[n-1][index].get_xticklabels():\n",
    "            tick_x.set_fontsize(13)\n",
    "\n",
    "        #Muda o tamanho de yticklabels\n",
    "        for tick_y in g.axes[index][0].get_yticklabels():\n",
    "            tick_y.set_fontsize(13)\n",
    "\n",
    "        #Muda o tamanho de xlabel/ylabel\n",
    "        g.axes[n-1][index].xaxis.label.set_size(15)\n",
    "        g.axes[index][0].yaxis.label.set_size(15)\n",
    "\n",
    "    #Muda tamanho das legendas\n",
    "    g.fig.get_children()[-1].properties()['title'].set_fontsize(15)\n",
    "    g.fig.get_children()[-1].prop.set_size(15)\n",
    "    plt.show()\n",
    "    \n",
    "'''Plot da variância explicada do PCA'''\n",
    "def plot_pca(pca,size):\n",
    "    #Plot dos 'size' primeiros PC's\n",
    "    x_list = []\n",
    "    for i in range(size):\n",
    "        x_list.append('PC' + str(i+1))\n",
    "\n",
    "    #Criando figura\n",
    "    fig,ax = plt.subplots(figsize=(15,7))\n",
    "    ax.set_title('Explained variance by different principal components')\n",
    "    ax.bar(height=pca.explained_variance_ratio_[0:size],x=x_list,width=0.9,label='Individual')\n",
    "    ax.plot(x_list,np.cumsum(pca.explained_variance_ratio_[0:size]),marker='o',color='orange',label='Cumulative')\n",
    "    \n",
    "    #Rotaciona xticklabels em 45 graus\n",
    "    for xtick in ax.get_xticklabels():\n",
    "        xtick.set_rotation(45)\n",
    "    \n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    \n",
    "'''Plot dos loagind vectors do PCA com os dados transformados.'''\n",
    "def plot_pca_loading(df_pca,df_loading,hue=None):\n",
    "    \n",
    "    #Criando figura\n",
    "    fig , ax = plt.subplots(figsize=(9,7))\n",
    "\n",
    "    #Scatterplot\n",
    "    sns.scatterplot(x='PC1',y='PC2',data=df_pca,hue=hue,palette='seismic',ax=ax)\n",
    "\n",
    "    #Setando limites nos eixos\n",
    "    ax.set_xlim(-1,1.5)\n",
    "    ax.set_ylim(-1,1.5)\n",
    "\n",
    "    #Linhas de referencia\n",
    "    ax.hlines(0,-1.5,1.5, linestyles='dotted', colors='grey')\n",
    "    ax.vlines(0,-1.5,1.5, linestyles='dotted', colors='grey')\n",
    "\n",
    "    #Labels em x/y\n",
    "    ax.set_xlabel('First Principal Component')\n",
    "    ax.set_ylabel('Second Principal Component')\n",
    "\n",
    "    #Plot dos labels e vetores\n",
    "    offset = 1.3 #Offset para separar os labels dos vetores\n",
    "    shift = 0.05 #Shift dos labels com os vetores\n",
    "    for index,value in df_loading.iterrows():\n",
    "        #Labels\n",
    "        ax.annotate(index, (value['V1']*offset+shift, value['V2']*offset), color='darkblue',fontsize=15)\n",
    "\n",
    "        #Vetores\n",
    "        ax.arrow(0,0,value['V1']*offset, value['V2']*offset,color='black',width=0.02)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "'''Aplica a transformação pca nos dados.'''\n",
    "def pca_transform(pca,df,n):\n",
    "    #Criando dataframe a partir da transformacao do pca\n",
    "    df_pca = pd.DataFrame(pca.transform(df)[:,0:n])\n",
    "\n",
    "    #Loading vectors\n",
    "    df_loading = pd.DataFrame(pca.components_,index=df.columns,columns=['V' + str(i+1) for i in range(len(pca.components_))])\n",
    "\n",
    "    #Renomeando colunas\n",
    "    df_pca.columns = ['PC' + str(c+1) for c in df_pca.columns]\n",
    "    \n",
    "    return df_pca,df_loading\n",
    "\n",
    "'''Plota um gráfico de radar.'''\n",
    "def radar_plot(df):\n",
    "        \n",
    "    #Numero de features\n",
    "    features = df.columns.values\n",
    "    N = len(features)\n",
    "\n",
    "    #Deixando em maiusculo\n",
    "    features = [i.upper() for i in features]\n",
    "\n",
    "    #Inicializa figura\n",
    "    plt.figure(figsize=(7,7))\n",
    "    ax = plt.subplot(111, polar=True)\n",
    "    ax.set_title('Comparação das características em cada grupo')\n",
    "\n",
    "    #Plota um radar plot para cada amostra\n",
    "    for i in range(len(df)):\n",
    "\n",
    "        #Valores a serem plotados\n",
    "        values = df.iloc[i].values.tolist()\n",
    "\n",
    "        #Angulos para o plot\n",
    "        angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "\n",
    "        #Tornando circular\n",
    "        values += values[:1]\n",
    "        angles += angles[:1]\n",
    "\n",
    "        # Draw one axe per variable + add labels labels yet\n",
    "        plt.xticks(angles[:-1], features, color='grey', size=13)\n",
    "\n",
    "        #Plot os dados\n",
    "        ax.plot(angles, values, linewidth=1, linestyle='solid')\n",
    "\n",
    "        #Preenche area\n",
    "        ax.fill(angles, values, 'b', alpha=0.1)\n",
    "\n",
    "    #Ylabels\n",
    "    ax.set_rlabel_position(0)\n",
    "    yticks = np.linspace(df.values.min(),df.values.max(),4)\n",
    "    plt.yticks(yticks[:-1], [str(round(i,2)) for i in yticks[:-1]], color=\"grey\", size=13)\n",
    "    plt.ylim(0,yticks[-1])\n",
    "        \n",
    "    #Legenda\n",
    "    ax.legend(['Grupo ' + str(i) for i in range(len(df))])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando o PCA\n",
    "pca = PCA().fit(df_cbd)\n",
    "\n",
    "#Plot dos PC's\n",
    "plot_pca(pca,df_cbd.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Até o quinto PC temos aproximadamente 90% de explicação dos dados. Logo, vamos utilizar os 5 primeiros componentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando dados\n",
    "df_pca,df_loading = pca_transform(pca,df_cbd,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos aplicar a clusterização nos dados após o PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando KMeans\n",
    "kmeans = KMeans(n_clusters=4,random_state=0).fit(df_pca.select_dtypes('float'))\n",
    "\n",
    "#Predizendo classes\n",
    "df_pca['target'] = kmeans.predict(df_pca.select_dtypes('float'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos plotar os dados para ver o que podemos interpretar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtrando pelos valores necessarios para o plot\n",
    "df_loading = df_loading.loc[['pse','psp','pspf'],['V1','V2']]\n",
    "\n",
    "# PCA plot\n",
    "plot_pca_loading(df_pca,df_loading,'target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver pela figura acima que o grupo 0 possui os maiores,menores valores de PSP,PSE respectivamente. Assim, provavelmente esse grupo é o que mais sofreu efeito do CBD. \n",
    "\n",
    "O grupo 1 é o oposto do 0, logo, tais pessoas não sofreram tanto efeito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Clusterização sem PCA em features no domínio da frequência\n",
    "\n",
    "Muitos dos atributos gerados não possuem um significado interessante para avaliar os clusters. Por causa disso faremos uma clusterização nos seguintes atributos:\n",
    "\n",
    "- psp\n",
    "- pse\n",
    "- pspf\n",
    "\n",
    "E então avaliaremos os resultados também."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copiando dados\n",
    "df_plot = df_cbd[['psp','pse','pspf']].copy()\n",
    "\n",
    "#Criando KMeans\n",
    "kmeans = KMeans(n_clusters=2,random_state=0).fit(df_plot)\n",
    "\n",
    "#Predizendo as classes\n",
    "df_plot['target'] = kmeans.predict(df_plot)\n",
    "\n",
    "#Scatterplot\n",
    "fig,ax = plt.subplots(figsize=(9,7))\n",
    "sns.scatterplot(x='psp',y='pse',data=df_plot,palette='seismic',hue='target',ax=ax)\n",
    "plt.show()\n",
    "\n",
    "#Radar plot\n",
    "radar_plot(df_plot.groupby('target').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_placebo = df_placebo[['psp','pse','pspf']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_placebo['target'] = df_plot['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatterplot\n",
    "fig,ax = plt.subplots(figsize=(9,7))\n",
    "sns.scatterplot(x='psp',y='pse',data=df_placebo,palette='seismic',hue='target',ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que o grupo 0 é o mais afetado pelo CBD enquanto o 1 seria o oposto.\n",
    "\n",
    "Lembrando que valores maiores de psp indicam movimentos mais regulares e valores menores de pse indicam movimentos mais suaves.\n",
    "\n",
    "No radar plot acima podemos verificar a média dos dois grupos. Note que a tendência do 0 é as pessoas terem um efeito maior sobre o CBD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Estatísticas dos clusters\n",
    "\n",
    "Pelas modelagens acima verificamos que é possível utilizar duas abordagens, ou seja, em ambas conseguimos bons resultados.\n",
    "\n",
    "Iremos a seguir trabalhar em cima da clusterização sem PCA nos atributos pse, psp e pspf para gerar estatísticas dos clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restaurando dados originais\n",
    "df_cbd = pd.DataFrame(mm.inverse_transform(df_cbd),columns=df_cbd.columns)\n",
    "\n",
    "#Salvando dados - criando um backup\n",
    "df_cbd[['pse','psp','pspf']].to_csv('parkinson_clustering.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leitura\n",
    "df_cbd = pd.read_csv('parkinson_clustering.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Realiza a clusterização com o kmeans\n",
    "    Retorna uma cópia do dataframe com a classe predita.\n",
    "'''\n",
    "def clustering(df,normalize=True,n_clusters=2):\n",
    "    \n",
    "    #Copia dataframe\n",
    "    df_cluster = df.copy()\n",
    "    \n",
    "    #Normaliza\n",
    "    if(normalize):\n",
    "        df_cluster = pd.DataFrame(MinMaxScaler().fit_transform(df_cluster),columns=df_cluster.columns)\n",
    "    \n",
    "    #Criando KMeans\n",
    "    kmeans = KMeans(n_clusters=n_clusters).fit(df_cluster)\n",
    "\n",
    "    #Predizendo clusters\n",
    "    df_cluster['target'] = kmeans.predict(df_cluster)\n",
    "    \n",
    "    return df_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clusterizando\n",
    "df_cluster = clustering(df_cbd,n_clusters=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estatísticas de cada grupo - média\n",
    "df_cluster.groupby('target').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pairplot\n",
    "pairplot(df_cluster,df_cluster.columns[:-1],'target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos verificar se existem diferenças significativas nos grupos em pse e psp por meio da ANOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANOVA\n",
    "_,pvalue = f_oneway(df_cluster.loc[df_cluster['target'] == 0].select_dtypes('float'),df_cluster.loc[df_cluster['target'] == 1].select_dtypes('float'))\n",
    "dict(zip(df_cluster.columns.values[:-1],pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pelo ANOVA verificamos que existem diferenças nos grupos em todos os atributos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
