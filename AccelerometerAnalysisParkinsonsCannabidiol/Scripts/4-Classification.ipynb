{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "Nosso principal objetivo na modelagem é realizar uma clusterização dos dados para posteriomente criar um sistema descritivo, ou seja, nossa meta é criar visualizações que possam ser úteis para os médicos.\n",
    "\n",
    "Assim, mesmo que os nossos dados possuam rótulos devidamente prontos nós tentaremos utilizar a clusterização. Contudo, inicialmente iremos utilizar algoritmos supervisionados para averiguar se os dados na forma como estão conseguem distinguir bem as classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,LabelEncoder\n",
    "from sklearn.feature_selection import RFE, SelectKBest, f_classif\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setando diretorio Data como o atual\n",
    "os.chdir('../Data')\n",
    "\n",
    "#Leitura dos dados\n",
    "# df_parkinson = pd.read_csv('parkinson_normalizado_ss.csv',index_col='name')\n",
    "# df_parkinson = pd.read_csv('parkinson_normalizado_mm.csv',index_col='name')\n",
    "df_parkinson = pd.read_csv('parkinson_pca.csv',index_col='name')\n",
    "\n",
    "#Mapeando dados para conseguir calcular o AUC\n",
    "df_parkinson['drug'] = df_parkinson['drug'].map({'CBD':1,'placebo':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modelagem\n",
    "\n",
    "## 2.1 Classificação\n",
    "\n",
    "Iremos realizar a modelagem com 3 algoritmos supervisionados:\n",
    "\n",
    "- Árvore de Decisão\n",
    "- Random Forest\n",
    "- Regressão Logística\n",
    "\n",
    "Como principal métrica de avaliaçã iremos utilizar o AUC (Área Under Curve) por nosso problema ser binário. De qualquer forma também iremos avaliar acurácia, sensibilidade, especificidade e erros para cada pessoa.\n",
    "\n",
    "Por fim, para garantir o poder generativo dos nossos algoritmos será utilizado uma variação do k-fold.\n",
    "\n",
    "Gostaríamos de lembrar que será utilizado os dados obtidos após a aplicação do PCA.\n",
    "\n",
    "### 2.1.1 Sem variáveis categórias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Realiza uma avaliação da classificação'''\n",
    "def evaluate_classifier(X,Y,split=1,type_clf='dt'):\n",
    "    \n",
    "    #Pessoas do dataset\n",
    "    unique_people = X.index.unique()\n",
    "\n",
    "    #Listas para armazenar os resultados finais\n",
    "    list_score = []\n",
    "    list_sens = []\n",
    "    list_spec = []\n",
    "    list_auc = []\n",
    "    list_error = []\n",
    "\n",
    "    for i in range(500):\n",
    "        if(split == 1):\n",
    "            #Sample das pessoas\n",
    "            people_train = np.random.choice(unique_people,size=11,replace=False)\n",
    "            people_test = unique_people[~unique_people.isin(people_train)]\n",
    "    \n",
    "            #Criando treino e test\n",
    "            X_train = X.loc[people_train]\n",
    "            Y_train = Y.loc[people_train]\n",
    "            X_test = X.loc[people_test]\n",
    "            Y_test = Y.loc[people_test]\n",
    "        elif(split == 2):\n",
    "            X_train,X_test,Y_train,Y_test = train_test_split(X,Y,stratify=Y,test_size=0.4)\n",
    "\n",
    "        #Criando classificador\n",
    "        if(type_clf == 'dt'):\n",
    "            clf = DecisionTreeClassifier().fit(X_train,Y_train)\n",
    "        elif(type_clf == 'rf'):\n",
    "            clf = RandomForestClassifier(n_estimators=100).fit(X_train,Y_train)\n",
    "        else:\n",
    "            clf = LogisticRegression(solver='liblinear',penalty='l1')\n",
    "\n",
    "        #Matrix de confusao\n",
    "        tn, fp, fn, tp = confusion_matrix(Y_test,clf.predict(X_test)).ravel()\n",
    "\n",
    "        #Sensibilidade\n",
    "        sens = tp/(tp+fn)\n",
    "        \n",
    "        #Especificidade\n",
    "        spec = tn/(tn+fp)\n",
    "\n",
    "        #Score\n",
    "        score = (tn+tp)/(tn+tp+fn+fp)\n",
    "        \n",
    "        #AUC\n",
    "        auc = roc_auc_score(Y_test,clf.predict(X_test))\n",
    "        \n",
    "        #Pessoas que erraram\n",
    "        error = (clf.predict(X_test) == Y_test)\n",
    "        list_error = np.append(list_error,error[error == False].index.unique().values)\n",
    "        list_score.append(score)\n",
    "        list_sens.append(sens)\n",
    "        list_spec.append(spec)\n",
    "        list_auc.append(auc)\n",
    "\n",
    "    print('AUC:',np.nanmean(list_auc))\n",
    "    print('Score:',np.nanmean(list_score))\n",
    "    print('Sensibilidade:',np.nanmean(list_sens))\n",
    "    print('Especificidade:',np.nanmean(list_spec),'\\n')\n",
    "    \n",
    "    #Calculo do erro por pessoa\n",
    "    error = pd.Series(list_error).value_counts()\n",
    "    print(error/error.values.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.517\n",
      "Score: 0.517\n",
      "Sensibilidade: 0.5176129032258063\n",
      "Especificidade: 0.5163870967741937 \n",
      "\n",
      "person_21    0.047114\n",
      "person_11    0.047018\n",
      "person_4     0.046827\n",
      "person_8     0.046732\n",
      "person_0     0.046636\n",
      "person_12    0.046636\n",
      "person_20    0.046541\n",
      "person_18    0.046254\n",
      "person_10    0.046158\n",
      "person_16    0.046063\n",
      "person_17    0.045967\n",
      "person_19    0.045776\n",
      "person_7     0.045585\n",
      "person_5     0.045585\n",
      "person_2     0.045298\n",
      "person_3     0.044629\n",
      "person_9     0.044343\n",
      "person_13    0.044151\n",
      "person_1     0.044151\n",
      "person_14    0.043865\n",
      "person_15    0.042336\n",
      "person_6     0.042336\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Separando dataset em variaveis dependentes e independentes\n",
    "X = df_parkinson.select_dtypes('float')\n",
    "Y = df_parkinson['drug']\n",
    "\n",
    "#Classificacao\n",
    "evaluate_classifier(X,Y,split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Variáveis categórias sem ser dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.4828441558441558\n",
      "Score: 0.4828441558441558\n",
      "Sensibilidade: 0.4737662337662338\n",
      "Especificidade: 0.4919220779220779 \n",
      "\n",
      "person_17    0.051492\n",
      "person_12    0.049491\n",
      "person_11    0.049309\n",
      "person_21    0.047853\n",
      "person_8     0.047489\n",
      "person_16    0.046397\n",
      "person_4     0.046397\n",
      "person_18    0.046215\n",
      "person_6     0.045852\n",
      "person_10    0.045488\n",
      "person_15    0.045488\n",
      "person_7     0.045306\n",
      "person_3     0.044942\n",
      "person_19    0.044942\n",
      "person_5     0.044578\n",
      "person_1     0.044214\n",
      "person_14    0.043850\n",
      "person_0     0.043304\n",
      "person_20    0.042940\n",
      "person_2     0.042394\n",
      "person_9     0.041303\n",
      "person_13    0.040757\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Separando dataset em variaveis dependentes e independentes\n",
    "X = df_parkinson.select_dtypes('float').copy()\n",
    "Y = df_parkinson['drug']\n",
    "\n",
    "#Adicionando variaveis categoricas\n",
    "X['measure'] = LabelEncoder().fit_transform(df_parkinson['measure'])\n",
    "X['evaluate'] = df_parkinson['evaluate']\n",
    "\n",
    "#Classificacao\n",
    "evaluate_classifier(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Variáveis categórias sendo dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.4855974025974026\n",
      "Score: 0.4855974025974026\n",
      "Sensibilidade: 0.47979220779220777\n",
      "Especificidade: 0.49140259740259734 \n",
      "\n",
      "person_20    0.048763\n",
      "person_10    0.048581\n",
      "person_4     0.048035\n",
      "person_3     0.047853\n",
      "person_21    0.047489\n",
      "person_13    0.047307\n",
      "person_14    0.047125\n",
      "person_5     0.046761\n",
      "person_18    0.046579\n",
      "person_2     0.045670\n",
      "person_0     0.045488\n",
      "person_8     0.045306\n",
      "person_1     0.045124\n",
      "person_7     0.045124\n",
      "person_15    0.044396\n",
      "person_11    0.043850\n",
      "person_17    0.043850\n",
      "person_6     0.043122\n",
      "person_16    0.042940\n",
      "person_19    0.042576\n",
      "person_12    0.042394\n",
      "person_9     0.041667\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Separando dataset em variaveis dependentes e independentes\n",
    "X = df_parkinson.select_dtypes('float').copy()\n",
    "Y = df_parkinson['drug']\n",
    "\n",
    "#Criando dummies\n",
    "X = pd.concat([X,pd.get_dummies(df_parkinson['measure'],prefix='measure'),pd.get_dummies(df_parkinson['evaluate'],prefix='evaluate')],axis=1)\n",
    "\n",
    "#Classificacao\n",
    "evaluate_classifier(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Váriveis categóricas sendo dummy, porém unidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5021168831168832\n",
      "Score: 0.5021168831168832\n",
      "Sensibilidade: 0.4995844155844155\n",
      "Especificidade: 0.5046493506493506 \n",
      "\n",
      "person_3     0.048745\n",
      "person_9     0.048563\n",
      "person_19    0.047472\n",
      "person_11    0.047108\n",
      "person_10    0.047108\n",
      "person_2     0.046199\n",
      "person_0     0.046199\n",
      "person_8     0.045835\n",
      "person_12    0.045653\n",
      "person_21    0.045653\n",
      "person_4     0.045289\n",
      "person_5     0.045289\n",
      "person_1     0.045107\n",
      "person_20    0.044744\n",
      "person_16    0.044562\n",
      "person_15    0.044562\n",
      "person_14    0.044562\n",
      "person_13    0.044016\n",
      "person_17    0.043652\n",
      "person_18    0.043470\n",
      "person_7     0.043107\n",
      "person_6     0.043107\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Separando dataset em variaveis dependentes e independentes\n",
    "X = df_parkinson.select_dtypes('float').copy()\n",
    "\n",
    "#Criando dummies\n",
    "X = pd.concat([X,pd.get_dummies(df_parkinson['measure'] + '_' + df_parkinson['evaluate'].map(lambda x: str(x)))],axis=1)\n",
    "\n",
    "#Classificacao\n",
    "evaluate_classifier(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A utilização de vários tipos de codificação para a variável fase e medida foram tentados por nossas análises mostrarem que existem diferenças dependendo da onde você olha.\n",
    "\n",
    "Contudo, independente da forma de codificação utilizada não conseguimos bons resultados. Esse fato ocorreu mesmo havendo uma variação dos algoritmos supervisionados.\n",
    "\n",
    "Acreditamos que essas codificações não derão certo por em cada fase/medida possuir um comportamente diferente. Vamos avaliar essa hipótese na próxima seção."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 Classificação considerando apenas uma fase e medida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtro selecionado a medida P na avaliação 1 com PC4 e PC5\n",
    "df_parkinson = df_parkinson.loc[(df_parkinson['measure'] == 'P') & (df_parkinson['evaluate'] == 1),['PC4','PC5','drug']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7513039682539683\n",
      "Score: 0.733090909090909\n",
      "Sensibilidade: 0.7125373015873016\n",
      "Especificidade: 0.790070634920635 \n",
      "\n",
      "person_8     0.149864\n",
      "person_0     0.117847\n",
      "person_15    0.081744\n",
      "person_11    0.080381\n",
      "person_7     0.079019\n",
      "person_2     0.075613\n",
      "person_17    0.072888\n",
      "person_18    0.055177\n",
      "person_6     0.053134\n",
      "person_19    0.049046\n",
      "person_3     0.029292\n",
      "person_9     0.029292\n",
      "person_21    0.027929\n",
      "person_1     0.026567\n",
      "person_16    0.020436\n",
      "person_14    0.018392\n",
      "person_12    0.016349\n",
      "person_20    0.009537\n",
      "person_13    0.002725\n",
      "person_5     0.002044\n",
      "person_4     0.002044\n",
      "person_10    0.000681\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Separando dataset em variaveis dependentes e independentes\n",
    "X = df_parkinson.loc[:,['PC4','PC5']]\n",
    "Y = df_parkinson['drug']\n",
    "\n",
    "#Classificacao\n",
    "evaluate_classifier(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que agora obtivemos bons resultados. Contudo isso foi a custa de uma grande diminuição da quantidade de amostras no dataset.\n",
    "\n",
    "Salientamos também que esse valor só foi possível de alcançar utilizando o PC4 e PC5. Qualquer outro componente utilizado acaba 'atrapalhando' na classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5 Uso de novas features\n",
    "\n",
    "Dado que não foi possível obter bons resultados com as features anteriores, iremos utilizar novos atributos para averiguar se conseguimos melhores valores.\n",
    "\n",
    "As novas features calculadas foram baseadas em https://github.com/Luke3D/CIS_PD-NDM que fez um trabalho similar com dados de Parkinson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pse</th>\n",
       "      <th>pspf1</th>\n",
       "      <th>pspf2</th>\n",
       "      <th>pspf3</th>\n",
       "      <th>psp1</th>\n",
       "      <th>psp2</th>\n",
       "      <th>psp3</th>\n",
       "      <th>wpsf</th>\n",
       "      <th>RMS</th>\n",
       "      <th>range</th>\n",
       "      <th>...</th>\n",
       "      <th>var</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>jerk_mean</th>\n",
       "      <th>jerk_std</th>\n",
       "      <th>jerk_skew</th>\n",
       "      <th>jerk_kur</th>\n",
       "      <th>evaluate</th>\n",
       "      <th>measure</th>\n",
       "      <th>drug</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>person_0</th>\n",
       "      <td>3.021855</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>17243.324518</td>\n",
       "      <td>1850.713750</td>\n",
       "      <td>1693.279040</td>\n",
       "      <td>17243.324518</td>\n",
       "      <td>382.050996</td>\n",
       "      <td>-6848.679085</td>\n",
       "      <td>...</td>\n",
       "      <td>363.377887</td>\n",
       "      <td>1.412557</td>\n",
       "      <td>30.949340</td>\n",
       "      <td>0.050528</td>\n",
       "      <td>535.257543</td>\n",
       "      <td>-0.163219</td>\n",
       "      <td>30.336621</td>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>placebo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_0</th>\n",
       "      <td>3.533303</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>39115.767987</td>\n",
       "      <td>13796.968242</td>\n",
       "      <td>5978.057257</td>\n",
       "      <td>39115.767987</td>\n",
       "      <td>390.853005</td>\n",
       "      <td>-3097.095783</td>\n",
       "      <td>...</td>\n",
       "      <td>908.940592</td>\n",
       "      <td>0.098040</td>\n",
       "      <td>4.969888</td>\n",
       "      <td>-0.922482</td>\n",
       "      <td>1153.757327</td>\n",
       "      <td>-0.175426</td>\n",
       "      <td>6.861516</td>\n",
       "      <td>2</td>\n",
       "      <td>P</td>\n",
       "      <td>placebo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_0</th>\n",
       "      <td>0.859185</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>129866.558198</td>\n",
       "      <td>3193.568772</td>\n",
       "      <td>1810.657041</td>\n",
       "      <td>129866.558198</td>\n",
       "      <td>397.813776</td>\n",
       "      <td>-6028.623410</td>\n",
       "      <td>...</td>\n",
       "      <td>630.078604</td>\n",
       "      <td>0.073222</td>\n",
       "      <td>2.749642</td>\n",
       "      <td>-0.111951</td>\n",
       "      <td>814.505179</td>\n",
       "      <td>0.168532</td>\n",
       "      <td>3.834549</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>placebo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_0</th>\n",
       "      <td>3.424263</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>102144.341817</td>\n",
       "      <td>60726.093359</td>\n",
       "      <td>42408.550846</td>\n",
       "      <td>102144.341817</td>\n",
       "      <td>470.023084</td>\n",
       "      <td>32858.801543</td>\n",
       "      <td>...</td>\n",
       "      <td>4939.505835</td>\n",
       "      <td>1.007991</td>\n",
       "      <td>0.771216</td>\n",
       "      <td>1.427418</td>\n",
       "      <td>6544.802604</td>\n",
       "      <td>0.251431</td>\n",
       "      <td>0.646722</td>\n",
       "      <td>2</td>\n",
       "      <td>S1</td>\n",
       "      <td>placebo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_0</th>\n",
       "      <td>2.009236</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>150065.780097</td>\n",
       "      <td>50565.746519</td>\n",
       "      <td>23406.888141</td>\n",
       "      <td>150065.780097</td>\n",
       "      <td>477.519118</td>\n",
       "      <td>10429.318103</td>\n",
       "      <td>...</td>\n",
       "      <td>4692.390496</td>\n",
       "      <td>2.259779</td>\n",
       "      <td>6.046340</td>\n",
       "      <td>2.919689</td>\n",
       "      <td>6994.739267</td>\n",
       "      <td>-0.003559</td>\n",
       "      <td>3.055311</td>\n",
       "      <td>2</td>\n",
       "      <td>S2</td>\n",
       "      <td>placebo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               pse  pspf1  pspf2  pspf3           psp1          psp2  \\\n",
       "name                                                                   \n",
       "person_0  3.021855      1      8     17   17243.324518   1850.713750   \n",
       "person_0  3.533303      1      3      6   39115.767987  13796.968242   \n",
       "person_0  0.859185      1      4     13  129866.558198   3193.568772   \n",
       "person_0  3.424263      1      4      7  102144.341817  60726.093359   \n",
       "person_0  2.009236      1      3      5  150065.780097  50565.746519   \n",
       "\n",
       "                  psp3           wpsf         RMS         range   ...     \\\n",
       "name                                                              ...      \n",
       "person_0   1693.279040   17243.324518  382.050996  -6848.679085   ...      \n",
       "person_0   5978.057257   39115.767987  390.853005  -3097.095783   ...      \n",
       "person_0   1810.657041  129866.558198  397.813776  -6028.623410   ...      \n",
       "person_0  42408.550846  102144.341817  470.023084  32858.801543   ...      \n",
       "person_0  23406.888141  150065.780097  477.519118  10429.318103   ...      \n",
       "\n",
       "                  var      skew       kurt  jerk_mean     jerk_std  jerk_skew  \\\n",
       "name                                                                            \n",
       "person_0   363.377887  1.412557  30.949340   0.050528   535.257543  -0.163219   \n",
       "person_0   908.940592  0.098040   4.969888  -0.922482  1153.757327  -0.175426   \n",
       "person_0   630.078604  0.073222   2.749642  -0.111951   814.505179   0.168532   \n",
       "person_0  4939.505835  1.007991   0.771216   1.427418  6544.802604   0.251431   \n",
       "person_0  4692.390496  2.259779   6.046340   2.919689  6994.739267  -0.003559   \n",
       "\n",
       "           jerk_kur  evaluate  measure     drug  \n",
       "name                                             \n",
       "person_0  30.336621         2        B  placebo  \n",
       "person_0   6.861516         2        P  placebo  \n",
       "person_0   3.834549         2        A  placebo  \n",
       "person_0   0.646722         2       S1  placebo  \n",
       "person_0   3.055311         2       S2  placebo  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setando diretorio Data como o atual\n",
    "os.chdir('../Data')\n",
    "\n",
    "#Leitura\n",
    "df_parkinson = pd.read_csv('parkinson_v2.csv',index_col = 'name')\n",
    "\n",
    "#Apresentação de algumas linhas\n",
    "df_parkinson.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicação das novas features:\n",
    "\n",
    "- jerk_(mean|std|skew|kur): Média, desvio padrão, assimetria e curtose para a série temporal com lag1.\n",
    "- RMS: Root mean square da série temporal.\n",
    "- range: Intervalo da série temporal.\n",
    "- mean: Médida da série temporal.\n",
    "- var: Variância da série temporal.\n",
    "- skew: Assimetria da série temporal.\n",
    "- kurt: Curtose da série temporal.\n",
    "\n",
    "Vamos fazer algumas mudanças nos dados como criar novas colunas e aplicar a boxcox para normalizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapenado droga como variavel numerica\n",
    "df_parkinson['drug'] = LabelEncoder().fit_transform(df_parkinson['drug'])\n",
    "\n",
    "#Criacao de novas colunas\n",
    "df_parkinson['wpsf2'] = df_parkinson['pspf2'] * df_parkinson['psp2']\n",
    "df_parkinson['wpsf3'] = df_parkinson['pspf3'] * df_parkinson['psp3']\n",
    "df_parkinson.rename(columns={'wpsf':'wpsf1'},inplace=True)\n",
    "\n",
    "#Arrumando posicao das colunas\n",
    "cols = list(df_parkinson.columns[0:8]) + ['wpsf2','wpsf3','jerk_mean', 'jerk_std','jerk_skew', 'jerk_kur','RMS','range', 'mean', 'var', 'skew', 'kurt','evaluate','measure','drug']\n",
    "df_parkinson = df_parkinson.loc[:,cols]\n",
    "\n",
    "#Aplicando log\n",
    "positive_cols = (df_parkinson <= 0).any()\n",
    "positive_cols = positive_cols[~positive_cols].index\n",
    "positive_cols = positive_cols.drop('evaluate')\n",
    "df_parkinson.loc[:,positive_cols] = np.log(df_parkinson.loc[:,positive_cols])\n",
    "\n",
    "#Reescalando variaveis\n",
    "mm = MinMaxScaler().fit(df_parkinson.iloc[:,:-3])\n",
    "df_parkinson.iloc[:,:-3] = mm.transform(df_parkinson.iloc[:,:-3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como possuímos 18 atríbutos, utilizararemos o <b>forward selection</b> para selecionar as melhores features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('wpsf2', 'jerk_skew', 'jerk_kur')\n",
      "AUC: 0.5375844155844156\n",
      "Score: 0.5375844155844155\n",
      "Sensibilidade: 0.5271168831168832\n",
      "Especificidade: 0.548051948051948 \n",
      "\n",
      "person_7     0.049273\n",
      "person_9     0.049091\n",
      "person_16    0.048727\n",
      "person_18    0.048000\n",
      "person_6     0.047091\n",
      "person_20    0.047091\n",
      "person_13    0.046545\n",
      "person_17    0.046364\n",
      "person_19    0.046182\n",
      "person_12    0.046000\n",
      "person_5     0.045636\n",
      "person_3     0.045636\n",
      "person_2     0.045273\n",
      "person_8     0.044727\n",
      "person_0     0.044545\n",
      "person_11    0.044182\n",
      "person_1     0.044000\n",
      "person_14    0.044000\n",
      "person_10    0.043636\n",
      "person_4     0.043091\n",
      "person_15    0.042727\n",
      "person_21    0.038182\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Arvore de decisao sera usada\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "#Criando foward selection\n",
    "sfs1 = sfs(dt,k_features=3,forward=True,floating=False,scoring='roc_auc',cv=5)\n",
    "\n",
    "#Divisao do dataset\n",
    "X = df_parkinson.iloc[:,:-3]\n",
    "Y = df_parkinson['drug']\n",
    "\n",
    "#Selecao\n",
    "sfs1 = sfs1.fit(X,Y)\n",
    "print(sfs1.k_feature_names_)\n",
    "\n",
    "#Classificacao\n",
    "evaluate_classifier(X.loc[:,sfs1.k_feature_names_],Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em vários testes realizados manualmente, vimos que não foi possível obter bons resultados. \n",
    "\n",
    "Assim, utilizamos a mesma ideia anterior de realizar uma filtragem por fase/medida.\n",
    "\n",
    "Com a ajuda do forward selection concluímos que para cada fase/medida deveríamos utilizar os seguintes atributos:\n",
    "\n",
    "| Medida       | Fase     | Features     |\n",
    "| :------------- | :----------: | -----------: |\n",
    "| P | 1 | psp3, pspf3, jerk_mean|\n",
    "| P | 2 | psp1, pspf1, jerk_mean|\n",
    "| B | 1 | pspf3, wpsf3, jerk_std, range|\n",
    "| B | 2 | pspf1, pspf3, var, jerk_std|\n",
    "| A | 1 | Nenhum|\n",
    "| A | 2 | wpsf2, kurt, jerk_kur|\n",
    "| S1 | 1 | pse, kurt, jerk_mean|\n",
    "| S1 | 2 | Nenhum|\n",
    "| S2 | 1 | Nenhum|\n",
    "| S2 | 2 | psp1, psp3|\n",
    "| F1 | 1 | psp2, jerk_kur|\n",
    "| F1 | 2 | pspf2, kurt, jerk_kur|\n",
    "| F2 | 1 | pspf1, kurt|\n",
    "| F2 | 2 | pspf1, pspf2|\n",
    "\n",
    "\n",
    "Sabemos por trabalhos similares que a classificação utilizando dados de acelerômetro para o problema de predizer pessoas com/sem Parkinson são bem difíceis. Por exemplo, conforme podemos ver aqui https://blog.insightdatascience.com/head-over-heels-detecting-parkinsons-disease-from-accelerometer-data-b36aa46e320b, houve uma dificuldade muito grande em obter bons atributos sendo que muitos deles tinham uma enorme sobreposição de classes.\n",
    "\n",
    "Sendo assim, nós tivemos as mesmas dificuldades mesmo que o nosso problema seja um pouco diferente. Em várias de nossas tentativas não foi possível obter resultados satisfatórios.\n",
    "\n",
    "A única 'solução' encontrada foi utilizar filtros nas fases/medidas conforme a tabela acima. Contudo, essa proposta não é viável, já que, a utilização da filtagrem acarreta em pouquíssimos dados, não sendo possível validar os modelos.\n",
    "\n",
    "É interessante notar, portanto, que segundo nossas análises temos que para cada fase/medida as features se comportam de uma maneira diferente, ou seja, dependendo da situação a distribuição delas no espaço muda. Isso pode ter acontecido pelo fato de que em cada fase nós temos níveis de estresse diferente. A mudança nas medidas pode ter envolvimento com o fator psicológico, já que, na segunda avaliação as pessoas estavam mais preparadas para o discurso. \n",
    "\n",
    "Nota-se também o porque da utilização de várias codificações não terem dado certo. Como cada fase/medida possui seu própio conjunto ótimo de features, mesmo que tentassemos realizar uma separação espacial nos dados a mistura de atributos ocasionava confusões no algoritmo.\n",
    "\n",
    "Portanto, concluímos que com os dados disponíveis não é possível realizar uma classificação satisfatória. Futuramente, o uso de novas features pode resolver o problema. Caso o contrário, a sugestão seria obter mais dados para que as avaliações fossem mais precisas. \n",
    "\n",
    "Mesmo não sendo ideal para validação, abaixo temos uma demo de como são os resultados da classificação utilizando a filtragem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7944746031746032\n",
      "Score: 0.78\n",
      "Sensibilidade: 0.8007222222222222\n",
      "Especificidade: 0.7882269841269842 \n",
      "\n",
      "person_14    0.180992\n",
      "person_10    0.102479\n",
      "person_16    0.098347\n",
      "person_0     0.093388\n",
      "person_7     0.086777\n",
      "person_11    0.065289\n",
      "person_21    0.060331\n",
      "person_2     0.057851\n",
      "person_8     0.042975\n",
      "person_18    0.033058\n",
      "person_19    0.030579\n",
      "person_9     0.023967\n",
      "person_3     0.021488\n",
      "person_20    0.016529\n",
      "person_17    0.016529\n",
      "person_5     0.015702\n",
      "person_13    0.013223\n",
      "person_4     0.011570\n",
      "person_15    0.009917\n",
      "person_12    0.009091\n",
      "person_1     0.004959\n",
      "person_6     0.004959\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# FILTRO - TESTE\n",
    "df_test = df_parkinson.loc[(df_parkinson['measure'] == 'P') & (df_parkinson['evaluate'] == 2),['psp1','pspf1','jerk_mean','drug']]\n",
    "\n",
    "#Separando dataset em variaveis  dependentes e independentes\n",
    "X = df_test.select_dtypes('float')\n",
    "Y = df_test['drug']\n",
    "\n",
    "#Classificacao\n",
    "evaluate_classifier(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conclusão\n",
    "\n",
    "- Não foi possível obter bons resultados.\n",
    "- Causas: Grande aleatoriedade nos dados pelo fato dos diferentes níveis de estresse que as pessoas passavam.\n",
    "- Possíveis soluções futuras: Descoberta de novos atributos e mais dados.\n",
    "\n",
    "## 4. Observações\n",
    "\n",
    "Como não foi possível obter resultados satisfatórios com a classificação, certamente o uso de um algoritmo não supervisionado para descrever os dados iria agir de maneira menos precisa, já que, o poder dos algoritmos superviosionados tende a ser maior.\n",
    "\n",
    "Assim, não iremos nos ater a criar ou realizar análises de clustering com esses dados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
