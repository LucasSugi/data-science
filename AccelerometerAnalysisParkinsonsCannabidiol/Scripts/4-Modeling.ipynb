{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "Vamos realizar uma modelagem dos dados com algoritmos de machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,LabelEncoder\n",
    "from sklearn.feature_selection import RFE, SelectKBest, f_classif\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setando diretorio Data como o atual\n",
    "os.chdir('../Data')\n",
    "\n",
    "#Leitura dos dados\n",
    "# df_parkinson = pd.read_csv('parkinson_normalizado_ss.csv',index_col='name')\n",
    "# df_parkinson = pd.read_csv('parkinson_normalizado_mm.csv',index_col='name')\n",
    "df_parkinson = pd.read_csv('parkinson_pca.csv',index_col='name')\n",
    "\n",
    "#Mapeando dados para conseguir calcular o AUC\n",
    "df_parkinson['drug'] = df_parkinson['drug'].map({'CBD':1,'placebo':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modelagem\n",
    "\n",
    "## 2.1 Classificação\n",
    "\n",
    "### 2.1.1 Sem variáveis categórias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(X,Y,split=1):\n",
    "    \n",
    "    #Pessoas do dataset\n",
    "    unique_people = X.index.unique()\n",
    "\n",
    "    #Listas para armazenar os resultados finais\n",
    "    list_score = []\n",
    "    list_sens = []\n",
    "    list_spec = []\n",
    "    list_auc = []\n",
    "    list_error = []\n",
    "\n",
    "    for i in range(500):\n",
    "        if(split == 1):\n",
    "            #Sample das pessoas\n",
    "            people_train = np.random.choice(unique_people,size=11,replace=False)\n",
    "            people_test = unique_people[~unique_people.isin(people_train)]\n",
    "    \n",
    "            #Criando treino e test\n",
    "            X_train = X.loc[people_train]\n",
    "            Y_train = Y.loc[people_train]\n",
    "            X_test = X.loc[people_test]\n",
    "            Y_test = Y.loc[people_test]\n",
    "        elif(split == 2):\n",
    "            X_train,X_test,Y_train,Y_test = train_test_split(X,Y,stratify=Y,test_size=0.4)\n",
    "\n",
    "        #Criando classificador\n",
    "        dt = DecisionTreeClassifier().fit(X_train,Y_train)\n",
    "\n",
    "        #Matrix de confusao\n",
    "        tn, fp, fn, tp = confusion_matrix(Y_test,dt.predict(X_test)).ravel()\n",
    "\n",
    "        #Sensibilidade\n",
    "        sens = tp/(tp+fn)\n",
    "        \n",
    "        #Especificidade\n",
    "        spec = tn/(tn+fp)\n",
    "\n",
    "        #Score\n",
    "        score = (tn+tp)/(tn+tp+fn+fp)\n",
    "        \n",
    "        #AUC\n",
    "        auc = roc_auc_score(Y_test,dt.predict(X_test))\n",
    "        \n",
    "        #Pessoas que erraram\n",
    "        error = (dt.predict(X_test) == Y_test)\n",
    "        list_error = np.append(list_error,error[error == False].index.unique().values)\n",
    "        list_score.append(score)\n",
    "        list_sens.append(sens)\n",
    "        list_spec.append(spec)\n",
    "        list_auc.append(auc)\n",
    "\n",
    "    print('AUC:',np.nanmean(list_auc))\n",
    "    print('Score:',np.nanmean(list_score))\n",
    "    print('Sensibilidade:',np.nanmean(list_sens))\n",
    "    print('Especificidade:',np.nanmean(list_spec),'\\n')\n",
    "    \n",
    "    #Calculo do erro por pessoa\n",
    "    error = pd.Series(list_error).value_counts()\n",
    "    print(error/error.values.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_parkinson = df_parkinson.loc[(df_parkinson['measure'] == 'P') & (df_parkinson['evaluate'] == 1),['PC4','PC5','drug']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando dataset em variaveis dependentes e independentes\n",
    "X = df_parkinson.select_dtypes('float')\n",
    "Y = df_parkinson['drug']\n",
    "\n",
    "#Classificacao\n",
    "classifier(X,Y,split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Variáveis categórias sem ser dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando dataset em variaveis dependentes e independentes\n",
    "X = df_parkinson.select_dtypes('float').copy()\n",
    "Y = df_parkinson['drug']\n",
    "\n",
    "#Adicionando variaveis categoricas\n",
    "X['measure'] = LabelEncoder().fit_transform(df_parkinson['measure'])\n",
    "X['evaluate'] = df_parkinson['evaluate']\n",
    "\n",
    "#Classificacao\n",
    "classifier(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Variáveis categórias sendo dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando dataset em variaveis dependentes e independentes\n",
    "X = df_parkinson.select_dtypes('float').copy()\n",
    "Y = df_parkinson['drug']\n",
    "\n",
    "#Criando dummies\n",
    "X = pd.concat([X,pd.get_dummies(df_parkinson['measure'],prefix='measure'),pd.get_dummies(df_parkinson['evaluate'],prefix='evaluate')],axis=1)\n",
    "\n",
    "#Classificacao\n",
    "classifier(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Váriveis categóricas sendo dummy, porém unidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando dataset em variaveis dependentes e independentes\n",
    "X = df_parkinson.select_dtypes('float').copy()\n",
    "\n",
    "#Criando dummies\n",
    "X = pd.concat([X,pd.get_dummies(df_parkinson['measure'] + '_' + df_parkinson['evaluate'].map(lambda x: str(x)))],axis=1)\n",
    "\n",
    "#Classificacao\n",
    "classifier(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Clusterização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divisão dataset\n",
    "X = df_parkinson.select_dtypes('float')\n",
    "\n",
    "#Clusterizacao\n",
    "kmeans = KMeans(n_clusters=2).fit(X)\n",
    "\n",
    "#Labels preditos pelo kmeans\n",
    "X['label'] = kmeans.predict(X)\n",
    "\n",
    "#Pairplot\n",
    "sns.pairplot(data=X,vars=['PC4','PC5'],hue='label')\n",
    "plt.show()\n",
    "\n",
    "#Pairplot\n",
    "sns.pairplot(data=df_parkinson,vars=['PC4','PC5'],hue='drug')\n",
    "plt.show()\n",
    "\n",
    "#Swap\n",
    "X['label'] = X['label'].map({0:1,1:0})\n",
    "\n",
    "(X['label'] == df_parkinson['drug']).sum() / X.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
