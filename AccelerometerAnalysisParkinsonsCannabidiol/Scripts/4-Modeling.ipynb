{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "Nosso principal objetivo na modelagem é realizar uma clusterização dos dados para posteriomente criar um sistema descritivo, ou seja, nossa meta é criar visualizações que possam ser úteis para os médicos.\n",
    "\n",
    "Assim, mesmo que os nossos dados possuam rótulos devidamente prontos nós tentaremos utilizar a clusterização. Contudo, inicialmente iremos utilizar algoritmos supervisionados para averiguar se os dados na forma como estão conseguem distinguir bem as classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,LabelEncoder\n",
    "from sklearn.feature_selection import RFE, SelectKBest, f_classif\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setando diretorio Data como o atual\n",
    "os.chdir('../Data')\n",
    "\n",
    "#Leitura dos dados\n",
    "# df_parkinson = pd.read_csv('parkinson_normalizado_ss.csv',index_col='name')\n",
    "# df_parkinson = pd.read_csv('parkinson_normalizado_mm.csv',index_col='name')\n",
    "df_parkinson = pd.read_csv('parkinson_pca.csv',index_col='name')\n",
    "\n",
    "#Mapeando dados para conseguir calcular o AUC\n",
    "df_parkinson['drug'] = df_parkinson['drug'].map({'CBD':1,'placebo':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modelagem\n",
    "\n",
    "## 2.1 Classificação\n",
    "\n",
    "Iremos realizar a modelagem com 3 algoritmos supervisionados:\n",
    "\n",
    "- Árvore de Decisão\n",
    "- Random Forest\n",
    "- Regressão Logística\n",
    "\n",
    "Como principal métrica de avaliaçã iremos utilizar o AUC (Área Under Curve) por nosso problema ser binário. De qualquer forma também iremos avaliar acurácia, sensibilidade, especificidade e erros para cada pessoa.\n",
    "\n",
    "Por fim, para garantir o poder generativo dos nossos algoritmos será utilizado uma variação do k-fold.\n",
    "\n",
    "Gostaríamos de lembrar que será utilizado os dados obtidos após a aplicação do PCA.\n",
    "\n",
    "### 2.1.1 Sem variáveis categórias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Realiza uma avaliação da classificação'''\n",
    "def evaluate_classifier(X,Y,split=1,type_clf='dt'):\n",
    "    \n",
    "    #Pessoas do dataset\n",
    "    unique_people = X.index.unique()\n",
    "\n",
    "    #Listas para armazenar os resultados finais\n",
    "    list_score = []\n",
    "    list_sens = []\n",
    "    list_spec = []\n",
    "    list_auc = []\n",
    "    list_error = []\n",
    "\n",
    "    for i in range(500):\n",
    "        if(split == 1):\n",
    "            #Sample das pessoas\n",
    "            people_train = np.random.choice(unique_people,size=11,replace=False)\n",
    "            people_test = unique_people[~unique_people.isin(people_train)]\n",
    "    \n",
    "            #Criando treino e test\n",
    "            X_train = X.loc[people_train]\n",
    "            Y_train = Y.loc[people_train]\n",
    "            X_test = X.loc[people_test]\n",
    "            Y_test = Y.loc[people_test]\n",
    "        elif(split == 2):\n",
    "            X_train,X_test,Y_train,Y_test = train_test_split(X,Y,stratify=Y,test_size=0.4)\n",
    "\n",
    "        #Criando classificador\n",
    "        if(type_clf == 'dt'):\n",
    "            clf = DecisionTreeClassifier().fit(X_train,Y_train)\n",
    "        elif(type_clf == 'rf'):\n",
    "            clf = RandomForestClassifier(n_estimators=100).fit(X_train,Y_train)\n",
    "        else:\n",
    "            clf = LogisticRegression(solver='liblinear',penalty='l1')\n",
    "\n",
    "        #Matrix de confusao\n",
    "        tn, fp, fn, tp = confusion_matrix(Y_test,clf.predict(X_test)).ravel()\n",
    "\n",
    "        #Sensibilidade\n",
    "        sens = tp/(tp+fn)\n",
    "        \n",
    "        #Especificidade\n",
    "        spec = tn/(tn+fp)\n",
    "\n",
    "        #Score\n",
    "        score = (tn+tp)/(tn+tp+fn+fp)\n",
    "        \n",
    "        #AUC\n",
    "        auc = roc_auc_score(Y_test,clf.predict(X_test))\n",
    "        \n",
    "        #Pessoas que erraram\n",
    "        error = (clf.predict(X_test) == Y_test)\n",
    "        list_error = np.append(list_error,error[error == False].index.unique().values)\n",
    "        list_score.append(score)\n",
    "        list_sens.append(sens)\n",
    "        list_spec.append(spec)\n",
    "        list_auc.append(auc)\n",
    "\n",
    "    print('AUC:',np.nanmean(list_auc))\n",
    "    print('Score:',np.nanmean(list_score))\n",
    "    print('Sensibilidade:',np.nanmean(list_sens))\n",
    "    print('Especificidade:',np.nanmean(list_spec),'\\n')\n",
    "    \n",
    "    #Calculo do erro por pessoa\n",
    "    error = pd.Series(list_error).value_counts()\n",
    "    print(error/error.values.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5169193548387098\n",
      "Score: 0.5169193548387098\n",
      "Sensibilidade: 0.5142903225806451\n",
      "Especificidade: 0.5195483870967742 \n",
      "\n",
      "person_10    0.047209\n",
      "person_12    0.046923\n",
      "person_4     0.046923\n",
      "person_8     0.046636\n",
      "person_18    0.046636\n",
      "person_19    0.046541\n",
      "person_16    0.046445\n",
      "person_7     0.046445\n",
      "person_11    0.046349\n",
      "person_21    0.046063\n",
      "person_17    0.046063\n",
      "person_20    0.046063\n",
      "person_2     0.045967\n",
      "person_0     0.045872\n",
      "person_13    0.045298\n",
      "person_5     0.045203\n",
      "person_3     0.043865\n",
      "person_14    0.043769\n",
      "person_1     0.043578\n",
      "person_15    0.043291\n",
      "person_9     0.042527\n",
      "person_6     0.042336\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Separando dataset em variaveis dependentes e independentes\n",
    "X = df_parkinson.select_dtypes('float')\n",
    "Y = df_parkinson['drug']\n",
    "\n",
    "#Classificacao\n",
    "evaluate_classifier(X,Y,split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Variáveis categórias sem ser dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.4798961038961039\n",
      "Score: 0.4798961038961039\n",
      "Sensibilidade: 0.47553246753246753\n",
      "Especificidade: 0.48425974025974017 \n",
      "\n",
      "person_20    0.050638\n",
      "person_2     0.048998\n",
      "person_7     0.047359\n",
      "person_18    0.046995\n",
      "person_17    0.046812\n",
      "person_1     0.046084\n",
      "person_16    0.045537\n",
      "person_13    0.045173\n",
      "person_4     0.045173\n",
      "person_12    0.045173\n",
      "person_14    0.044991\n",
      "person_21    0.044627\n",
      "person_8     0.044627\n",
      "person_0     0.044627\n",
      "person_15    0.044627\n",
      "person_9     0.044627\n",
      "person_19    0.044627\n",
      "person_5     0.044627\n",
      "person_10    0.044444\n",
      "person_11    0.044080\n",
      "person_6     0.043534\n",
      "person_3     0.042623\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Separando dataset em variaveis dependentes e independentes\n",
    "X = df_parkinson.select_dtypes('float').copy()\n",
    "Y = df_parkinson['drug']\n",
    "\n",
    "#Adicionando variaveis categoricas\n",
    "X['measure'] = LabelEncoder().fit_transform(df_parkinson['measure'])\n",
    "X['evaluate'] = df_parkinson['evaluate']\n",
    "\n",
    "#Classificacao\n",
    "evaluate_classifier(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Variáveis categórias sendo dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.4842987012987013\n",
      "Score: 0.4842987012987013\n",
      "Sensibilidade: 0.4781558441558441\n",
      "Especificidade: 0.4904415584415584 \n",
      "\n",
      "person_6     0.049353\n",
      "person_12    0.046986\n",
      "person_9     0.046986\n",
      "person_3     0.046986\n",
      "person_2     0.046986\n",
      "person_17    0.046440\n",
      "person_20    0.046440\n",
      "person_21    0.046258\n",
      "person_15    0.046075\n",
      "person_8     0.046075\n",
      "person_16    0.045893\n",
      "person_14    0.045711\n",
      "person_13    0.045711\n",
      "person_18    0.045347\n",
      "person_10    0.045347\n",
      "person_11    0.044983\n",
      "person_5     0.044983\n",
      "person_4     0.044436\n",
      "person_0     0.043708\n",
      "person_19    0.042433\n",
      "person_1     0.042069\n",
      "person_7     0.040794\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Separando dataset em variaveis dependentes e independentes\n",
    "X = df_parkinson.select_dtypes('float').copy()\n",
    "Y = df_parkinson['drug']\n",
    "\n",
    "#Criando dummies\n",
    "X = pd.concat([X,pd.get_dummies(df_parkinson['measure'],prefix='measure'),pd.get_dummies(df_parkinson['evaluate'],prefix='evaluate')],axis=1)\n",
    "\n",
    "#Classificacao\n",
    "evaluate_classifier(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Váriveis categóricas sendo dummy, porém unidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5025324675324675\n",
      "Score: 0.5025324675324675\n",
      "Sensibilidade: 0.4959480519480519\n",
      "Especificidade: 0.5091168831168831 \n",
      "\n",
      "person_9     0.048372\n",
      "person_18    0.047827\n",
      "person_5     0.047463\n",
      "person_12    0.047463\n",
      "person_14    0.047281\n",
      "person_8     0.046918\n",
      "person_13    0.046918\n",
      "person_21    0.046554\n",
      "person_16    0.046372\n",
      "person_19    0.046372\n",
      "person_2     0.046190\n",
      "person_4     0.045827\n",
      "person_10    0.045645\n",
      "person_6     0.045645\n",
      "person_15    0.044554\n",
      "person_1     0.044190\n",
      "person_7     0.044190\n",
      "person_0     0.043826\n",
      "person_20    0.043644\n",
      "person_11    0.042008\n",
      "person_3     0.041826\n",
      "person_17    0.040917\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Separando dataset em variaveis dependentes e independentes\n",
    "X = df_parkinson.select_dtypes('float').copy()\n",
    "\n",
    "#Criando dummies\n",
    "X = pd.concat([X,pd.get_dummies(df_parkinson['measure'] + '_' + df_parkinson['evaluate'].map(lambda x: str(x)))],axis=1)\n",
    "\n",
    "#Classificacao\n",
    "evaluate_classifier(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A utilização de vários tipos de codificação para a variável fase e medida foram tentados por nossas análises mostrarem que existem diferenças dependendo da onde você olha.\n",
    "\n",
    "Contudo, independente da forma de codificação utilizada não conseguimos bons resultados. Esse fato ocorreu mesmo havendo uma variação dos algoritmos supervisionados.\n",
    "\n",
    "Acreditamos que essas codificações não derão certo por em cada fase/medida possuir um comportamente diferente. Vamos avaliar essa hipótese na próxima seção."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 Classificação considerando apenas uma fase e medida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtro selecionado a medida P na avaliação 1 com PC4 e PC5\n",
    "df_parkinson = df_parkinson.loc[(df_parkinson['measure'] == 'P') & (df_parkinson['evaluate'] == 1),['PC4','PC5','drug']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7508103174603175\n",
      "Score: 0.7356363636363636\n",
      "Sensibilidade: 0.7303984126984125\n",
      "Especificidade: 0.7712222222222223 \n",
      "\n",
      "person_8     0.149243\n",
      "person_0     0.128611\n",
      "person_15    0.087345\n",
      "person_7     0.077029\n",
      "person_17    0.072902\n",
      "person_18    0.066713\n",
      "person_19    0.061898\n",
      "person_11    0.061210\n",
      "person_2     0.057084\n",
      "person_6     0.047455\n",
      "person_9     0.039890\n",
      "person_3     0.039890\n",
      "person_21    0.024072\n",
      "person_16    0.022008\n",
      "person_12    0.017882\n",
      "person_1     0.017882\n",
      "person_14    0.014443\n",
      "person_20    0.011692\n",
      "person_13    0.002751\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Separando dataset em variaveis dependentes e independentes\n",
    "X = df_parkinson.loc[:,['PC4','PC5']]\n",
    "Y = df_parkinson['drug']\n",
    "\n",
    "#Classificacao\n",
    "evaluate_classifier(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que agora obtivemos bons resultados. Contudo isso foi a custa de uma grande diminuição da quantidade de amostras no dataset.\n",
    "\n",
    "Salientamos também que esse valor só foi possível de alcançar utilizando o PC4 e PC5. Qualquer outro componente utilizado acaba 'atrapalhando' na classificação."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
